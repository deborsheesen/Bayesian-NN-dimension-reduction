{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reference for HMC: Figure 2 of https://arxiv.org/pdf/1206.1901.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, numpy.random as npr, torch.nn as nn, copy, timeit, torch\n",
    "from torch.distributions.bernoulli import Bernoulli \n",
    "from HMCfunctions import *\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import plot, show, legend"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Have a class \"model\" that gives log-likelihood and gradient of log-likelihood:\n",
    "\n",
    "abstract class model (must have log-likelihood and gradient)\n",
    "sub class: whatever models we are interested in "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class general HMC \n",
    "class leapfrog \n",
    "takes in model\n",
    "model has gradient and log-likelihood \n",
    "etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient w.r.t. $\\theta$:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\log p(\\theta \\mid \\sigma, x_{1:n}, y_{1:n}) \n",
    "= \n",
    "- \\sum_{i=1}^n \\frac{\\left ( \\mu_\\theta(x_i) - y_i \\right ) \\, \\nabla_\\theta \\mu_\\theta(x_i) }{\\sigma^{2k}} + \\nabla_\\theta \\log p_0(\\theta) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 1\n",
    "n_h1 = 5\n",
    "n_out = 2\n",
    "\n",
    "nn_model = nn.Sequential(nn.Linear(n_in, n_h1),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(n_h1, n_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Total number of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in nn_model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Randomly initialise model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=5, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=5, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.apply(init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate some random data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nobs = 100\n",
    "x = torch.rand(nobs, n_in)\n",
    "y = np.zeros((nobs, n_out))\n",
    "for i in range(nobs) :\n",
    "    y[:,0] = list(np.cos(2*np.pi*x))\n",
    "    y[:,1] = list(np.sin(2*np.pi*x))\n",
    "y = torch.from_numpy(y).float()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get dimensions of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes =  [torch.Size([5, 1]), torch.Size([5]), torch.Size([2, 5]), torch.Size([2])]\n"
     ]
    }
   ],
   "source": [
    "shapes = get_shapes(nn_model)\n",
    "print(\"Shapes = \", shapes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(10) :\n",
    "    current_nn_model = copy.deepcopy(nn_model)\n",
    "    proposed_mom, current_mom, proposed_nn_model = leapfrog(nn_model, n_leapfrog, delta_leapfrog, shapes)\n",
    "    print(criterion(current_nn_model(x),y).data/criterion(proposed_nn_model(x),y).data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for param in nn_model.parameters() :\n",
    "    print(\"Param, grad:\", param.data, param.grad)\n",
    "    \n",
    "update_grads(nn_model, x, y)\n",
    "\n",
    "for param in nn_model.parameters() :\n",
    "    print(\"Param, grad:\", param.data, param.grad)\n",
    "    \n",
    "print(\"Loss:\", nn.MSELoss()(nn_model(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  HMC\n",
    "\n",
    "* First define the MCMC chain and randomly initialise it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2_000\n",
    "chain = []\n",
    "for shape in shapes :\n",
    "    chain_shape = list(shape)\n",
    "    chain_shape.insert(0,T)\n",
    "    chain.append(torch.randn(chain_shape, requires_grad=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then run HMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta_leapfrog = 1e-1\n",
    "n_leapfrog = 10\n",
    "sigma = 1\n",
    "nn_model.apply(init_normal)\n",
    "n_accept = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter    200/2000 after     0.9 sec | accept_rate 0.555\n",
      "iter    400/2000 after     1.8 sec | accept_rate 0.562\n",
      "iter    600/2000 after     2.7 sec | accept_rate 0.563\n",
      "iter    800/2000 after     3.5 sec | accept_rate 0.559\n",
      "iter   1000/2000 after     4.4 sec | accept_rate 0.560\n",
      "iter   1200/2000 after     5.2 sec | accept_rate 0.557\n",
      "iter   1400/2000 after     6.1 sec | accept_rate 0.556\n",
      "iter   1600/2000 after     6.9 sec | accept_rate 0.553\n",
      "iter   1800/2000 after     7.8 sec | accept_rate 0.554\n",
      "iter   2000/2000 after     8.6 sec | accept_rate 0.551\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "for t in range(T) : \n",
    "    updated_nn_model, a = HMC_1step(nn_model, n_leapfrog, delta_leapfrog, shapes, x, y, criterion, sigma)\n",
    "    n_accept += a\n",
    "    for (i,param) in enumerate(nn_model.parameters()) :\n",
    "        chain[i][t] = param.data\n",
    "        \n",
    "    if ((t+1) % 200 == 0) or (t+1) == T :\n",
    "        accept_rate = float(n_accept) / float(t+1)\n",
    "        print(\"iter %6d/%d after %7.1f sec | accept_rate %.3f\" % (\n",
    "            t+1, T, time() - start_time, accept_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESS's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESS: 979/2000\n",
      "ESS: 833/2000\n",
      "ESS: 1104/2000\n",
      "ESS: 1120/2000\n",
      "ESS: 938/2000\n",
      "ESS: 934/2000\n",
      "ESS: 827/2000\n",
      "ESS: 1142/2000\n",
      "ESS: 731/2000\n",
      "ESS: 979/2000\n",
      "ESS: 1023/2000\n",
      "ESS: 835/2000\n",
      "ESS: 1017/2000\n",
      "ESS: 996/2000\n",
      "ESS: 952/2000\n",
      "ESS: 1133/2000\n",
      "ESS: 871/2000\n",
      "ESS: 886/2000\n",
      "ESS: 871/2000\n",
      "ESS: 1056/2000\n",
      "ESS: 1166/2000\n",
      "ESS: 1258/2000\n"
     ]
    }
   ],
   "source": [
    "find_ESS(chain, shapes, True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
