{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Reference for HMC: Figure 2 of https://arxiv.org/pdf/1206.1901.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, numpy.random as npr, torch.nn as nn, copy, timeit, torch\n",
    "from torch.distributions.bernoulli import Bernoulli \n",
    "from tqdm import trange\n",
    "from HMCfunctions import *\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import plot, show, legend"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Have a class \"model\" that gives log-likelihood and gradient of log-likelihood:\n",
    "\n",
    "abstract class model (must have log-likelihood and gradient)\n",
    "sub class: whatever models we are interested in "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class general HMC \n",
    "class leapfrog \n",
    "takes in model\n",
    "model has gradient and log-likelihood \n",
    "etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient w.r.t. $\\theta$:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\log p(\\theta \\mid \\sigma, x_{1:n}, y_{1:n}) \n",
    "= \n",
    "- \\sum_{i=1}^n \\frac{\\left ( \\mu_\\theta(x_i) - y_i \\right ) \\, \\nabla_\\theta \\mu_\\theta(x_i) }{\\sigma^{2k}} + \\nabla_\\theta \\log p_0(\\theta) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_in = 1\n",
    "n_h1 = 5\n",
    "# n_h2 = 10\n",
    "n_out = 2\n",
    "\n",
    "nn_model = nn.Sequential(nn.Linear(n_in, n_h1),\n",
    "                         nn.Tanh(),\n",
    "                         nn.Linear(n_h1, n_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Total number of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in nn_model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Randomly initialise model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=5, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=5, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.apply(init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate some random data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nobs = 10_000\n",
    "x = torch.rand(nobs, n_in)\n",
    "y = np.zeros((nobs, n_out))\n",
    "y[:,0] = list(np.cos(2*np.pi*x))\n",
    "y[:,1] = list(np.sin(2*np.pi*x))\n",
    "y = torch.from_numpy(y).float()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get dimensions of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes =  [torch.Size([5, 1]), torch.Size([5]), torch.Size([2, 5]), torch.Size([2])]\n"
     ]
    }
   ],
   "source": [
    "shapes = get_shapes(nn_model)\n",
    "print(\"Shapes = \", shapes)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(10) :\n",
    "    current_nn_model = copy.deepcopy(nn_model)\n",
    "    proposed_mom, current_mom, proposed_nn_model = leapfrog(nn_model, n_leapfrog, delta_leapfrog, shapes)\n",
    "    print(criterion(current_nn_model(x),y).data/criterion(proposed_nn_model(x),y).data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for param in nn_model.parameters() :\n",
    "    print(\"Param, grad:\", param.data, param.grad)\n",
    "    \n",
    "update_grads(nn_model, x, y)\n",
    "\n",
    "for param in nn_model.parameters() :\n",
    "    print(\"Param, grad:\", param.data, param.grad)\n",
    "    \n",
    "print(\"Loss:\", nn.MSELoss()(nn_model(x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  HMC\n",
    "\n",
    "* First define the MCMC chain and randomly initialise it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 10_000\n",
    "chain = []\n",
    "for shape in shapes :\n",
    "    chain_shape = list(shape)\n",
    "    chain_shape.insert(0,T)\n",
    "    chain.append(torch.randn(chain_shape, requires_grad=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then run HMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "delta_leapfrog = 5e-3\n",
    "n_leapfrog = 25\n",
    "prior_sigma = 1\n",
    "error_sigma = 1\n",
    "nn_model.apply(init_normal)\n",
    "update_grads(nn_model, x, y)\n",
    "n_accept = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1002/10000 [00:54<07:45, 19.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   1000/10000 after    54.1 sec | accept_rate 0.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2002/10000 [01:44<06:45, 19.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   2000/10000 after   104.7 sec | accept_rate 0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3002/10000 [02:35<05:54, 19.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   3000/10000 after   155.4 sec | accept_rate 0.828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4003/10000 [03:26<04:58, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   4000/10000 after   206.1 sec | accept_rate 0.838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5003/10000 [04:16<04:13, 19.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   5000/10000 after   256.6 sec | accept_rate 0.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6004/10000 [05:06<02:55, 22.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   6000/10000 after   306.5 sec | accept_rate 0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7003/10000 [05:56<02:10, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   7000/10000 after   355.9 sec | accept_rate 0.851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8003/10000 [06:43<01:41, 19.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   8000/10000 after   403.7 sec | accept_rate 0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9003/10000 [07:36<00:50, 19.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter   9000/10000 after   456.1 sec | accept_rate 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [08:24<00:00, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  10000/10000 after   504.2 sec | accept_rate 0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "for t in trange(T) : \n",
    "    nn_model, a = HMC_1step(nn_model, n_leapfrog, delta_leapfrog, shapes, x, y, criterion, prior_sigma)\n",
    "    n_accept += a\n",
    "    update_grads(nn_model, x, y)\n",
    "    for (i,param) in enumerate(nn_model.parameters()) :\n",
    "        chain[i][t] = param.data\n",
    "        \n",
    "    if ((t+1) % (int(T/10)) == 0) or (t+1) == T :\n",
    "        accept_rate = float(n_accept) / float(t+1)\n",
    "        print(\"iter %6d/%d after %7.1f sec | accept_rate %.3f\" % (\n",
    "            t+1, T, time() - start_time, accept_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESS's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ESS, means, Vars = find_ESS(chain, shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzgAAACcCAYAAACz6Q7nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZlVxv8Hznb3tuy/k4cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1008x144 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ms = 5\n",
    "plt.figure(figsize=(14,2))\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.subplot(131)\n",
    "plt.plot(ESS, 'o', markersize=ms)\n",
    "plt.title(\"ESSs\")\n",
    "plt.subplot(132)\n",
    "plt.plot(means, 'o', markersize=ms)\n",
    "plt.title(\"Posterior means\")\n",
    "plt.subplot(133)\n",
    "plt.plot(Vars, 'o', markersize=ms)\n",
    "plt.title(\"Posterior variances\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7,  97,  31, 106,  12,  47,  61,  30, 107,  16,  33,  58,  45,\n",
       "        72,  24,  20,  42,  59,  77,  11,  50,  72])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is some bug, because the posterior seems to be basically the prior. Increasing the number of data points does not seem to make any difference, only the prior variance makes a difference. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(nn_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1000  loss:  0.4030824899673462\n",
      "epoch:  2000  loss:  0.3654867112636566\n",
      "epoch:  3000  loss:  0.3555649220943451\n",
      "epoch:  4000  loss:  0.3529464900493622\n",
      "epoch:  5000  loss:  0.3522554636001587\n",
      "epoch:  6000  loss:  0.3520731031894684\n",
      "epoch:  7000  loss:  0.35202497243881226\n",
      "epoch:  8000  loss:  0.3520122468471527\n",
      "epoch:  9000  loss:  0.3520089089870453\n",
      "epoch:  10000  loss:  0.35200801491737366\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10_000):\n",
    "    # Forward Propagation\n",
    "    y_pred = nn_model(x)\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if (epoch+1)%1_000 == 0 :\n",
    "        print('epoch: ', epoch+1,' loss: ', loss.item())\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # perform a backward pass (backpropagation)\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0465],\n",
      "        [-1.9168]])\n",
      "tensor([-0.0425,  0.9472])\n"
     ]
    }
   ],
   "source": [
    "for param in nn_model.parameters() :\n",
    "    print(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
